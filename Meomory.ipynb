{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import (ConversationBufferMemory, \n",
    "                            ConversationSummaryMemory, \n",
    "                            ConversationBufferWindowMemory, \n",
    "                            ConversationKGMemory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "#Structure of Conversation chain\n",
    "print(conversation.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversational Memory types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Hello, how are you?', 'history': '', 'response': \"Hey there! I'm doing great, thanks for asking. How are you today?\"}\n"
     ]
    }
   ],
   "source": [
    "#ConversationBufferMemory\n",
    "# Stores all the conversation between user and AI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Updated prompt to include the history variable\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful chatbot which chats with the user like a human.\n",
    "    \n",
    "    {history}\n",
    "    user: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationBufferMemory()\n",
    ")\n",
    "\n",
    "# Invoke the conversation with input\n",
    "response = conversation.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello Large language model my name is Adwait and I am a AI engineer',\n",
       " 'history': \"Human: Hello, how are you?\\nAI: Hey there! I'm doing great, thanks for asking. How are you today?\",\n",
       " 'response': \"Hey Adwait!  It's nice to meet you.  An AI engineer, huh? That's awesome!  What kind of projects are you working on these days?\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Hello Large language model my name is Adwait and I am a AI engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Now tell me what is my name and what do I do?',\n",
       " 'history': \"Human: Hello, how are you?\\nAI: Hey there! I'm doing great, thanks for asking. How are you today?\\nHuman: Hello Large language model my name is Adwait and I am a AI engineer\\nAI: Hey Adwait!  It's nice to meet you.  An AI engineer, huh? That's awesome!  What kind of projects are you working on these days?\",\n",
       " 'response': \"You told me your name is Adwait and that you're an AI engineer.  Is there anything else I can help you with?\"}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Now tell me what is my name and what do I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Hello, how are you?', 'history': '', 'response': \"Hey there! I'm doing great, thanks for asking. How are you today?\"}\n"
     ]
    }
   ],
   "source": [
    "#ConversationSummaryMemory\n",
    "# Summarises all the conversation between user and AI\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Updated prompt to include the history variable\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful chatbot which chats with the user like a human.\n",
    "    \n",
    "    {history}\n",
    "    user: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationSummaryMemory(llm=llm)\n",
    ")\n",
    "\n",
    "# Invoke the conversation with input\n",
    "response = conversation.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello my name is Adwait and I am a AI engineer',\n",
       " 'history': 'The human greets the AI and asks how it is. The AI responds that it is doing great and asks how the human is doing.',\n",
       " 'response': \"Hey Adwait!  It's great to meet you.  An AI engineer, huh? That's awesome!  I'm doing great, thanks for asking. How are you doing today?\"}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Hello my name is Adwait and I am a AI engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Now tell me what is my name and what do I do?',\n",
       " 'history': 'The human greets the AI and asks how it is. The AI responds that it is doing great and asks how the human is doing.  The human introduces themself as Adwait, an AI engineer, which the AI finds awesome.',\n",
       " 'response': \"Hey there!  Doing great, thanks for asking.  How are you?\\n\\nOh, you're Adwait, an AI engineer? That's awesome!  So you're building the future, huh?  Pretty cool.\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Now tell me what is my name and what do I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Hello, how are you?', 'history': '', 'response': \"Hey there! I'm doing great, thanks for asking. How are you today?\"}\n"
     ]
    }
   ],
   "source": [
    "#ConversationBufferWindowMemory\n",
    "#We can select that how many pairs of recent conversation between user and AI must be stored in our memory\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Updated prompt to include the history variable\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful chatbot which chats with the user like a human.\n",
    "    \n",
    "    {history}\n",
    "    user: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationBufferWindowMemory(k=2)\n",
    ")\n",
    "\n",
    "# Invoke the conversation with input\n",
    "response = conversation.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I am doing great my name is Adwait and I am a AI engineer',\n",
       " 'history': \"Human: Hello, how are you?\\nAI: Hey there! I'm doing great, thanks for asking. How are you today?\",\n",
       " 'response': \"That's awesome, Adwait!  An AI engineer â€“ that's a really cool job.  What kind of projects are you working on at the moment?  Anything you can share?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"I am doing great my name is Adwait and I am a AI engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'we are working on various AI projects',\n",
       " 'history': \"Human: Hello, how are you?\\nAI: Hey there! I'm doing great, thanks for asking. How are you today?\\nHuman: I am doing great my name is Adwait and I am a AI engineer\\nAI: That's awesome, Adwait!  An AI engineer â€“ that's a really cool job.  What kind of projects are you working on at the moment?  Anything you can share?\",\n",
       " 'response': 'That\\'s exciting!  \"Various AI projects\" sounds intriguing.  Is there a particular area or type of AI that you\\'re most focused on right now?  For example, are you working with anything related to natural language processing, computer vision, reinforcement learning, or something else entirely?  I\\'m always curious to hear about what\\'s happening in the field.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"we are working on various AI projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Right now I am working on building a chatbot',\n",
       " 'history': 'Human: I am doing great my name is Adwait and I am a AI engineer\\nAI: That\\'s awesome, Adwait!  An AI engineer â€“ that\\'s a really cool job.  What kind of projects are you working on at the moment?  Anything you can share?\\nHuman: we are working on various AI projects\\nAI: That\\'s exciting!  \"Various AI projects\" sounds intriguing.  Is there a particular area or type of AI that you\\'re most focused on right now?  For example, are you working with anything related to natural language processing, computer vision, reinforcement learning, or something else entirely?  I\\'m always curious to hear about what\\'s happening in the field.',\n",
       " 'response': \"That's fantastic! Building a chatbot is a really interesting and challenging project.  What kind of chatbot are you building? Is it for customer service, entertainment, information retrieval, or something else?  And what technologies are you using?  I'm always fascinated by the different approaches people take.\"}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Right now I am working on building a chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I am building a generic chatbot from which any one can talk with it',\n",
       " 'history': 'Human: we are working on various AI projects\\nAI: That\\'s exciting!  \"Various AI projects\" sounds intriguing.  Is there a particular area or type of AI that you\\'re most focused on right now?  For example, are you working with anything related to natural language processing, computer vision, reinforcement learning, or something else entirely?  I\\'m always curious to hear about what\\'s happening in the field.\\nHuman: Right now I am working on building a chatbot\\nAI: That\\'s fantastic! Building a chatbot is a really interesting and challenging project.  What kind of chatbot are you building? Is it for customer service, entertainment, information retrieval, or something else?  And what technologies are you using?  I\\'m always fascinated by the different approaches people take.',\n",
       " 'response': \"That's ambitious!  A truly generic chatbot that can hold a conversation with anyone on any topic is a significant undertaking.  What's your approach to making it so versatile?  Are you using a large language model, a rule-based system, or a hybrid approach?  And what are some of the biggest challenges you're facing in building such a broad-ranging conversational AI? I'd love to hear more about your design and the hurdles you're overcoming.\"}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"I am building a generic chatbot from which any one can talk with it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Now tell me what is my name and what do I do?',\n",
       " 'history': \"Human: Right now I am working on building a chatbot\\nAI: That's fantastic! Building a chatbot is a really interesting and challenging project.  What kind of chatbot are you building? Is it for customer service, entertainment, information retrieval, or something else?  And what technologies are you using?  I'm always fascinated by the different approaches people take.\\nHuman: I am building a generic chatbot from which any one can talk with it\\nAI: That's ambitious!  A truly generic chatbot that can hold a conversation with anyone on any topic is a significant undertaking.  What's your approach to making it so versatile?  Are you using a large language model, a rule-based system, or a hybrid approach?  And what are some of the biggest challenges you're facing in building such a broad-ranging conversational AI? I'd love to hear more about your design and the hurdles you're overcoming.\",\n",
       " 'response': \"Oh, I apologize!  As a large language model, I have no memory of past conversations and don't have access to personal information about you unless you explicitly provide it.  I only know what you've told me in *this* current conversation â€“ that you're building a generic chatbot.  So, I don't know your name or what you do outside of that project.  Is there anything else I can help you with regarding your chatbot?\"}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Now tell me what is my name and what do I do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Hello, how are you?', 'history': '', 'response': \"Hey there! I'm doing great, thanks for asking. How are you today?\"}\n"
     ]
    }
   ],
   "source": [
    "#ConversationKnowledgeGraphMemory\n",
    "# Basically it only keeps all the knowledge of user based on the conversations with user and \n",
    "# AI instead of storing all the conversation, summary of conversations or recent conversations\n",
    "# so it only stores the knowledge for example name, age, likes, field whatever user has provided\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Updated prompt to include the history variable\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"You are a helpful chatbot which chats with the user like a human.\n",
    "    \n",
    "    {history}\n",
    "    user: {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=ConversationKGMemory(llm=llm)\n",
    ")\n",
    "\n",
    "# Invoke the conversation with input\n",
    "response = conversation.invoke(\"Hello, how are you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I am doing great my name is Adwait and I am a AI engineer',\n",
       " 'history': '',\n",
       " 'response': \"That's fantastic, Adwait!  AI engineering is a really exciting field.  It's great to hear you're doing well.  What are you working on at the moment, if you don't mind me asking?\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"I am doing great my name is Adwait and I am a AI engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'we are working on various AI projects',\n",
       " 'history': '',\n",
       " 'response': \"Oh, that's exciting!  What kinds of AI projects are you working on?  I'd love to hear more.  Are you focusing on a particular area, like natural language processing, computer vision, or something else?\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"we are working on various AI projects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Right now I am working on building a chatbot',\n",
       " 'history': '',\n",
       " 'response': \"Oh, cool!  Building a chatbot is a really interesting project.  What kind of chatbot are you working on?  Are you using any specific frameworks or languages?  I'd love to hear more about it!\"}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Right now I am working on building a chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'I am building a generic chatbot from which any one can talk with it',\n",
       " 'history': '',\n",
       " 'response': \"That's a fantastic project! Building a generic chatbot is a really ambitious undertaking.  What kind of functionality are you aiming for?  Are you focusing on a specific area, like customer service or casual conversation, or are you trying to make it as broadly applicable as possible?  I'm curious to hear more about your plans!  What technologies are you using?\"}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"I am building a generic chatbot from which any one can talk with it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'Now tell me what is my name and what do I do?',\n",
       " 'history': '',\n",
       " 'response': \"Oh, I'm so sorry, but I don't actually know your name or what you do!  I have no access to personal information about you unless you explicitly tell me.  To help me chat with you better, maybe you could tell me a little about yourself? ðŸ˜Š\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.invoke(\"Now tell me what is my name and what do I do?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
