{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"India News | Latest India News | Read latest and breaking news from India. Today's top India news headlines, news on Indian politics, elections, government, business, technology, and Bollywood. Today's Latest News: Read Latest Big news headlines from India and around the world with live coverage on India Today. ... Rishabh Pant opened up on his relationship with new India Test captain Shubman Gill and said that he gels really well with the 25-year-old on and off the field. Pant will act as Gill's deputy as he begins his time as the ... Israel-Iran Conflict Today LIVE News Updates: Trump posted that Israel now has 'complete and total control of the skies over Iran' Updated: June 18, 2025 01:30 IST 'Mohalla clinics promoted corruption, not public health': Delhi CM at launch of 33 Arogya Mandirs; AAP hits back Today's Latest News: Get the news headlines from India and around the world on Oneindia.com. Stay updated with today's news, live coverage, videos, and photos across politics, entertainment ... ABP LIVE: Latest News Updates from India and Across the world! Breaking News Alerts, Live News Updates on Politics, Business, Technology, Bollywood, Cricket, and More! ... Opinion: Australia Wants India Against China, But New Delhi Remains Cautious. India. Chinese Air Base Near Siliguri Border? Why Chicken's Neck Remains A Security Challenge ...\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "tool1 = DuckDuckGoSearchRun()\n",
    "tool1.invoke(\"Tell me about todays new in India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing command:\n",
      " dir\n",
      " Volume in drive C is Acer\n",
      " Volume Serial Number is E464-3CD8\n",
      "\n",
      " Directory of c:\\Users\\Adwait\\Desktop\\AIML\\Exploring-Langchain\\Agents\n",
      "\n",
      "20-06-2025  12:37    <DIR>          .\n",
      "05-05-2025  20:28    <DIR>          ..\n",
      "20-09-2024  10:45         2,215,244 attention.pdf\n",
      "19-06-2025  16:39            10,250 currency_exchange_tool.ipynb\n",
      "03-06-2025  10:41             1,038 current_wether_update.ipynb\n",
      "20-06-2025  10:08            16,887 learning_tools_in_detail.ipynb\n",
      "20-06-2025  12:30             1,518 test.py\n",
      "19-06-2025  17:11            12,672 tools.ipynb\n",
      "19-06-2025  17:18             6,732 tool_calling.ipynb\n",
      "               7 File(s)      2,264,341 bytes\n",
      "               2 Dir(s)  17,566,564,352 bytes free\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adwait\\Desktop\\AIML\\Exploring-Langchain\\env\\lib\\site-packages\\langchain_community\\tools\\shell\\tool.py:33: UserWarning: The shell tool has no safeguards by default. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#This tool is used to run the command on our command line \n",
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "tool2 = ShellTool()\n",
    "print(tool2.invoke(\"dir\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Given two numbers a and b this tool returns their product\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def text(a: int) -> str:\n",
    "    \"You will be given a number and your task will be to return the english spelling of that number\"\n",
    "    return f\"return the english spelling of {a} number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000252A47C18A0>, search_kwargs={})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = PyPDFLoader('attention.pdf')\n",
    "docs = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "db = FAISS.from_documents(documents, GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))\n",
    "retriever = db.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tool(name='PDF_QA', description='Useful when you want to answer questions from the PDF document.', func=<bound method Chain.run of RetrievalQA(verbose=False, combine_documents_chain=StuffDocumentsChain(verbose=False, llm_chain=LLMChain(verbose=False, prompt=ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], input_types={}, partial_variables={}, template='{question}'), additional_kwargs={})]), llm=ChatGoogleGenerativeAI(model='models/gemini-2.0-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x00000252A310A6B0>, default_metadata=()), output_parser=StrOutputParser(), llm_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['FAISS', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x00000252A47C18A0>, search_kwargs={}))>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import Tool\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tool = llm.bind_tools([multiply, text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I am a large language model. I don't have a name.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_tool.invoke(\"Hey how are you my name is adwait my I know your name?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 8.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--b98bcedd-501a-43e3-a0e7-1661f102f995-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 8.0}, 'id': '13028126-e117-4224-9c07-a701f16ed579', 'type': 'tool_call'}] usage_metadata={'input_tokens': 74, 'output_tokens': 5, 'total_tokens': 79, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm_tool.invoke(\"Can you multiply 2 with 8\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'name': 'text', 'arguments': '{\"a\": 2.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--8c32c377-9b8b-41ab-9e0b-6506c1df3b48-0' tool_calls=[{'name': 'text', 'args': {'a': 2.0}, 'id': '391c32a9-09a1-48fe-9e6e-1503d2392cb9', 'type': 'tool_call'}] usage_metadata={'input_tokens': 76, 'output_tokens': 3, 'total_tokens': 79, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm_tool.invoke(\"Can you tell me the english spelling of 2\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'function_call': {'name': 'multiply', 'arguments': '{\"a\": 2.0, \"b\": 6.0}'}} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []} id='run--7d6f0e27-16da-4596-b1fb-a68cdd9efd8a-0' tool_calls=[{'name': 'multiply', 'args': {'a': 2.0, 'b': 6.0}, 'id': 'fe199bcc-7ed1-4609-a6ec-05abafbb638d', 'type': 'tool_call'}] usage_metadata={'input_tokens': 83, 'output_tokens': 5, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "response = llm_tool.invoke(\"Can you multiple 2 with 6 and then tell me the english spelling of that\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2.0, 'b': 6.0},\n",
       "  'id': 'fe199bcc-7ed1-4609-a6ec-05abafbb638d',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the conclussion for the above code is that when we are binding tool with a LLM then at that time it LLM is only responsible to to call one tool it does not has the capability to chain the tools ony by one to provide the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# --- Add Memory ---\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  \n",
    "    return_messages=True         \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [multiply,\n",
    "                text,\n",
    "                Tool(\n",
    "                    name=\"PDF_QA\",\n",
    "                    func=qa_chain.run,\n",
    "                    description=\"Useful when you want to answer questions from the PDF document.\"\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    # memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to use the PDF_QA tool to answer the question about self-attention.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"PDF_QA\",\n",
      "  \"action_input\": \"What is self-attention?\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3mSelf-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have the answer to the question.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Tell me what is self attention', 'output': 'Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.'}\n"
     ]
    }
   ],
   "source": [
    "response = agent.invoke(\"\"\"Tell me what is self attention\"\"\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
